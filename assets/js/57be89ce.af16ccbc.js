"use strict";(self.webpackChunkproduct_help=self.webpackChunkproduct_help||[]).push([[266],{9257:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>i,metadata:()=>a,toc:()=>c});var o=n(5893),s=n(1151);const i={title:"Kubernetes Deployments",hide_title:!0,sidebar_position:5},r="Kubernetes Deployments Considerations",a={id:"cado-response/deploy/kubernetes",title:"Kubernetes Deployments",description:"Fundamental Principles",source:"@site/docs/cado-response/deploy/kubernetes.md",sourceDirName:"cado-response/deploy",slug:"/cado-response/deploy/kubernetes",permalink:"/cado-response/deploy/kubernetes",draft:!1,unlisted:!1,editUrl:"https://github.com/cado-security/product-help/tree/master/docs/cado-response/deploy/kubernetes.md",tags:[],version:"current",lastUpdatedAt:1708605681,formattedLastUpdatedAt:"Feb 22, 2024",sidebarPosition:5,frontMatter:{title:"Kubernetes Deployments",hide_title:!0,sidebar_position:5},sidebar:"tutorialSidebar",previous:{title:"Cross-Project Setup",permalink:"/cado-response/deploy/gcp/gcp-cross-project"},next:{title:"Overview",permalink:"/cado-response/discovery-import/intro"}},l={},c=[{value:"Fundamental Principles",id:"fundamental-principles",level:2},{value:"Overview of Execution and Authentication",id:"overview-of-execution-and-authentication",level:2},{value:"Private Clusters",id:"private-clusters",level:2},{value:"Kubernetes RBAC Requirements",id:"kubernetes-rbac-requirements",level:2},{value:"Distroless / No Shell Containers",id:"distroless--no-shell-containers",level:2},{value:"On-Premise Clusters",id:"on-premise-clusters",level:2},{value:"Alternative Collection Methods via other Agents or Sidecars",id:"alternative-collection-methods-via-other-agents-or-sidecars",level:2},{value:"Alternative Collection Methods via the Node Volume",id:"alternative-collection-methods-via-the-node-volume",level:2}];function d(e){const t={a:"a",h1:"h1",h2:"h2",li:"li",p:"p",ul:"ul",...(0,s.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.h1,{id:"kubernetes-deployments-considerations",children:"Kubernetes Deployments Considerations"}),"\n",(0,o.jsx)(t.h2,{id:"fundamental-principles",children:"Fundamental Principles"}),"\n",(0,o.jsx)(t.p,{children:"There is a balance between access to data during responding to breaches, and restricting data access in order to limit the likelihood of a breach. The notes below intend to help make these trade-off decisions when granting access to the Cado platform to your Kubernetes environments to respond to incidents and achieve defense in depth.\nPlease view the service specific pages for more detail on how to deploy and import data from specific Kubernetes implementations."}),"\n",(0,o.jsx)(t.h2,{id:"overview-of-execution-and-authentication",children:"Overview of Execution and Authentication"}),"\n",(0,o.jsx)(t.p,{children:"When acquiring data from Kubernetes containers, Cado executes a shell script to download the Cado Host binary, run it to collect forensic artifacts, and uploads the collected files to cloud storage for processing."}),"\n",(0,o.jsxs)(t.p,{children:["How this shell script is executed will depend upon the environment. For example ECS utilizes ECS execute, whereas EKS/AKS/GKE ",(0,o.jsx)(t.a,{href:"https://www.cadosecurity.com/how-we-sped-up-acquiring-forensic-data-from-aws-kubernetes-and-azure-kubernetes-services-by-10-times/",children:"utilize"})," the Kubernetes control plane API."]}),"\n",(0,o.jsx)(t.p,{children:"Depending upon the service, authenticating to the Kubernetes API may require both IAM and Kubernetes RBAC permissions. These permissions are described on the service specific documentation pages."}),"\n",(0,o.jsx)(t.h2,{id:"private-clusters",children:"Private Clusters"}),"\n",(0,o.jsx)(t.p,{children:"As the Cado platform requires access to the Kubernetes control plane API, these requires a valid route at the network level from the Cado instance to the Kubernetes API."}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"This is possible in AKS environments as Azure has created the \u201ccommand invoke\u201d command to execute commands against private AKS clusters."}),"\n",(0,o.jsx)(t.li,{children:"We are investigating support for private GKE clusters through public endpoints on private clusters."}),"\n",(0,o.jsx)(t.li,{children:"It is not currently possible to acquire from private EKS clusters, as AWS have not yet created an equivalent method of access to Azure\u2019s \u201ccommand invoke\u201d."}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"kubernetes-rbac-requirements",children:"Kubernetes RBAC Requirements"}),"\n",(0,o.jsx)(t.p,{children:"Cado requires both write and execute access to containers, in order to download and execute the Cado Host binary to collect forensic artifacts from side containers.\nIn particular, Cado requires \u2018get\u2019 and \u2018list\u2019 for the \u2018pods\u2019 resource, and \u2018get\u2019 and \u2018create\u2019 for the \u2018pods/exec\u2019 resource.\nCado Host can run as a normal user, not sudo, although less data may be acquired."}),"\n",(0,o.jsx)(t.h2,{id:"distroless--no-shell-containers",children:"Distroless / No Shell Containers"}),"\n",(0,o.jsxs)(t.p,{children:["The Cado platform cannot acquire artifacts from a container built with a ",(0,o.jsx)(t.a,{href:"https://github.com/GoogleContainerTools/distroless#why-should-i-use-distroless-images",children:"distroless"})," image. This is due to the way the platform interacts with a container, which requires a shell environment. Additionally, the platform will hide containers with the gcr.io/distroless image tag. You may be able to still collect data for the container via the \u201cAlternative Collection Methods via the Node Volume\u201d method below."]}),"\n",(0,o.jsx)(t.h2,{id:"on-premise-clusters",children:"On-Premise Clusters"}),"\n",(0,o.jsx)(t.p,{children:"If you are using an on-premise or otherwise custom implementation of Kubernetes, you may be able to collect data by executing the Cado Host shell script inside the container. See for example, the documentation for OpenShift. You may also be able to process the Volume of the node, if you have access to it (see \u201cCollecting the Node Volume\u201d below for more)."}),"\n",(0,o.jsx)(t.h2,{id:"alternative-collection-methods-via-other-agents-or-sidecars",children:"Alternative Collection Methods via other Agents or Sidecars"}),"\n",(0,o.jsxs)(t.p,{children:["If you are using an agent in your containers that has the ability to execute code,you may be able to collect data by manually deploying Cado Host inside the container for collection.\nA similar approach may be possible using a ",(0,o.jsx)(t.a,{href:"https://spacelift.io/blog/kubernetes-sidecar-container",children:"sidecar"})," container with access to the target container's data, manually deployed."]}),"\n",(0,o.jsx)(t.h2,{id:"alternative-collection-methods-via-the-node-volume",children:"Alternative Collection Methods via the Node Volume"}),"\n",(0,o.jsx)(t.p,{children:"If you cannot execute code inside the container, you may be able to process the Volume of the node running the container. For example, this approach is possible for EKS running on a cluster of EC2 nodes.\nIf using the Docker container runtime, the file system of containers will normally be available at /var/lib/docker/overlay2.\nIf using the Containerd runtime (which the latest versions of EKS now uses), the file system will not be immediately visible on the Volume. We are currently working on a method to support containerd volume level acquisitions."})]})}function u(e={}){const{wrapper:t}={...(0,s.a)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},1151:(e,t,n)=>{n.d(t,{Z:()=>a,a:()=>r});var o=n(7294);const s={},i=o.createContext(s);function r(e){const t=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),o.createElement(i.Provider,{value:t},e.children)}}}]);